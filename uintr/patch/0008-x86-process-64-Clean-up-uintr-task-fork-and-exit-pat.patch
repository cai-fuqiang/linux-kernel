From 4a6a66a6b38fbd7ea0294ba262ad65c81dc63325 Mon Sep 17 00:00:00 2001
From: Sohil Mehta <sohil.mehta@intel.com>
Date: Thu, 8 Sep 2022 13:32:59 -0700
Subject: [PATCH 08/18] x86/process/64: Clean up uintr task fork and exit paths

The user interrupt MSRs and the user interrupt state is task specific.
During task fork and exit clear the task state, clear the MSRs and
dereference the shared resources.

Some of the memory resources like the UPID are referenced in the file
descriptor and could be in use while the uvec_fd is still valid.
Instead of freeing up  the UPID just dereference it.  Eventually when
every user releases the reference the memory resource will be freed up.

Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
Signed-off-by: Sohil Mehta <sohil.mehta@intel.com>
---
 arch/x86/include/asm/uintr.h |  4 +++
 arch/x86/kernel/fpu/core.c   | 15 ++++++++++
 arch/x86/kernel/process.c    | 11 ++++++++
 arch/x86/kernel/uintr.c      | 53 ++++++++++++++++++++++++++++++++++++
 4 files changed, 83 insertions(+)

diff --git a/arch/x86/include/asm/uintr.h b/arch/x86/include/asm/uintr.h
index 2c8156c72cc0..636e2f4e7ef4 100644
--- a/arch/x86/include/asm/uintr.h
+++ b/arch/x86/include/asm/uintr.h
@@ -34,11 +34,15 @@ struct uintr_upid_ctx {
 void switch_uintr_prepare(struct task_struct *prev);
 void switch_uintr_return(void);
 
+void uintr_free(struct task_struct *task);
+
 #else /* !CONFIG_X86_USER_INTERRUPTS */
 
 static inline void switch_uintr_prepare(struct task_struct *prev) {}
 static inline void switch_uintr_return(void) {}
 
+static inline void uintr_free(struct task_struct *task) {}
+
 #endif /* CONFIG_X86_USER_INTERRUPTS */
 
 #endif /* _ASM_X86_UINTR_H */
diff --git a/arch/x86/kernel/fpu/core.c b/arch/x86/kernel/fpu/core.c
index 03801368d28f..4c2ebcbb877b 100644
--- a/arch/x86/kernel/fpu/core.c
+++ b/arch/x86/kernel/fpu/core.c
@@ -568,6 +568,7 @@ int fpu_clone(struct task_struct *dst, unsigned long clone_flags, bool minimal)
 {
 	struct fpu *src_fpu = &current->thread.fpu;
 	struct fpu *dst_fpu = &dst->thread.fpu;
+	struct uintr_state *uintr_state;
 
 	/* The new task's FPU state cannot be valid in the hardware. */
 	dst_fpu->last_cpu = -1;
@@ -615,6 +616,20 @@ int fpu_clone(struct task_struct *dst, unsigned long clone_flags, bool minimal)
 	save_fpregs_to_fpstate(dst_fpu);
 	if (!(clone_flags & CLONE_THREAD))
 		fpu_inherit_perms(dst_fpu);
+
+	/*
+	 * All of UINTR state is not expected to be inherited. The UPID related
+	 * structs are task specific. The UITT is same across a clone() but it
+	 * would be fixed up upon first execution of SENDUIPI.
+	 *
+	 * Check if the xsave header needs to be set to init value (like PASID)
+	 */
+	if (cpu_feature_enabled(X86_FEATURE_UINTR)) {
+		uintr_state = get_xsave_addr(&dst_fpu->fpstate->regs.xsave, XFEATURE_UINTR);
+		if (uintr_state)
+			memset(uintr_state, 0, sizeof(*uintr_state));
+	}
+
 	fpregs_unlock();
 
 	/*
diff --git a/arch/x86/kernel/process.c b/arch/x86/kernel/process.c
index 58a6ea472db9..29cff35d58b5 100644
--- a/arch/x86/kernel/process.c
+++ b/arch/x86/kernel/process.c
@@ -26,6 +26,7 @@
 #include <linux/elf-randomize.h>
 #include <trace/events/power.h>
 #include <linux/hw_breakpoint.h>
+#include <asm/uintr.h>
 #include <asm/cpu.h>
 #include <asm/apic.h>
 #include <linux/uaccess.h>
@@ -91,6 +92,14 @@ int arch_dup_task_struct(struct task_struct *dst, struct task_struct *src)
 #ifdef CONFIG_VM86
 	dst->thread.vm86 = NULL;
 #endif
+
+#ifdef CONFIG_X86_USER_INTERRUPTS
+	/* User Interrupt receiver upid state is unique for each task */
+	dst->thread.upid_ctx = NULL;
+
+	dst->thread.upid_activated = false;
+#endif
+
 	/* Drop the copied pointer to current's fpstate */
 	dst->thread.fpu.fpstate = NULL;
 
@@ -118,6 +127,8 @@ void exit_thread(struct task_struct *tsk)
 
 	free_vm86(t);
 
+	uintr_free(tsk);
+
 	fpu__drop(fpu);
 }
 
diff --git a/arch/x86/kernel/uintr.c b/arch/x86/kernel/uintr.c
index 8455b7a757ea..177de2a10119 100644
--- a/arch/x86/kernel/uintr.c
+++ b/arch/x86/kernel/uintr.c
@@ -353,3 +353,56 @@ void switch_uintr_return(void)
 	if (READ_ONCE(upid->puir))
 		apic->send_IPI_self(UINTR_NOTIFICATION_VECTOR);
 }
+
+/*
+ * This should only be called from exit_thread().
+ * exit_thread() can happen in current context when the current thread is
+ * exiting or it can happen for a new thread that is being created.
+ * For new threads is_uintr_task() will fail.
+ */
+void uintr_free(struct task_struct *t)
+{
+	struct uintr_upid_ctx *upid_ctx;
+	void *xstate;
+
+	if (!cpu_feature_enabled(X86_FEATURE_UINTR))
+		return;
+
+	upid_ctx = t->thread.upid_ctx;
+	if (is_uintr_receiver(t)) {
+		xstate = start_update_xsave_msrs(XFEATURE_UINTR);
+
+		xsave_wrmsrl(xstate, MSR_IA32_UINTR_MISC, 0);
+		xsave_wrmsrl(xstate, MSR_IA32_UINTR_TT, 0);
+		xsave_wrmsrl(xstate, MSR_IA32_UINTR_PD, 0);
+		xsave_wrmsrl(xstate, MSR_IA32_UINTR_RR, 0);
+		xsave_wrmsrl(xstate, MSR_IA32_UINTR_STACKADJUST, 0);
+		xsave_wrmsrl(xstate, MSR_IA32_UINTR_HANDLER, 0);
+
+		/* If upid is active, upid_ctx will be valid */
+		if (is_uintr_receiver(t)) {
+			/*
+			 * Suppress notifications so that no further interrupts are
+			 * generated based on this UPID.
+			 */
+			set_bit(UINTR_UPID_STATUS_SN, (unsigned long *)&upid_ctx->upid->nc.status);
+			put_upid_ref(upid_ctx);
+		}
+
+		t->thread.upid_activated = false;
+
+		end_update_xsave_msrs();
+	}
+
+	if (upid_ctx) {
+		put_upid_ref(t->thread.upid_ctx);
+		/*
+		 * This might not be needed since the thread is exiting. Have
+		 * it anyways to be safe.
+		 */
+		t->thread.upid_ctx = NULL;
+	}
+
+	//if (WARN_ON_ONCE(t != current))
+	//	return;
+}
-- 
2.39.0

