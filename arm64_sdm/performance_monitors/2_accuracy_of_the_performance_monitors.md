The Performance Monitors:

* Are a non-invasive debug component. See Non-invasive behavior.

* Must provide broadly accurate and statistically useful count information.

However, the Performance Monitors allow for:

* A reasonable degree of inaccuracy in the counts to keep the implementation
  and validation cost low. See A reasonable degree of inaccuracy on page
  D11-5249.
* IMPLEMENTATION DEFINED controls, such as those in ACTLR registers, that
  software must configure before using certain PMU events. For example, to
  configure how the PE generates PMU events for components such as external
  caches and external memory.
* Other IMPLEMENTATION DEFINED controls, such as those in ACTLR registers, to
  optionally put the PE in an operating state that might do one or both of
  the following:
  + Change the level of non-invasiveness of the Performance Monitors so that
    enabling an event counter can impact the performance or behavior of the PE.
  + Allow inaccurate counts. This includes, but is not limited to, cycle counts.

# D11.2.1 Non-invasive behavior

The Performance Monitors are a non-invasive debug feature. A non-invasive debug
feature permits the observation of data and program flow. Performance Monitors,
PC Sample-based Profiling and Trace are non-invasive debug features.

Non-invasive debug components do not guarantee that they do not make any
changes to the behavior or performance of the processor. Any changes that do
occur must not be severe however, as this will reduce the usefulness of event
counters for performance measurement and profiling. This does not include any
change to program behavior that results from the same program being
instrumented to use the Performance Monitors, or from some other performance
monitoring process being run concurrently with the process being profiled in a
multitasking operating system. As such, a reasonable variation in performance
is permissible.

> NOTE
>
> Power consumption is one measure of performance. Therefore, a reasonable
> variation in power consumption is permissible.

Arm does not define a reasonable variation in performance, but recommends that
such a variation is kept within 5% of normal operating performance, when
averaged across a suite of code that is representative of the application
workload.

> Note
> 
> For profiles other than A-profile, there is the potential for stronger
> requirements. Ultimately, performance requirements are determined by
> end-users, and not set by the architecture.

For some common architectural events, this requirement to be non-invasive can
conflict with the requirement to present an accurate value of the count under
normal operating conditions. Should an implementation require more
performance-invasive techniques to accurately count an event, there are the
following options:

* If the event is optional, define an alternative implementation defined event
  that accurately counts the event and document the impact on performance of
  enabling the event.

* Provide an implementation defined control that disables accurate counting of
  the event to restore broadly accurate performance, and document the impact on
  performance of accurate counting.

# D11.2.2 A reasonable degree of inaccuracy

The Performance Monitors provide broadly accurate and statistically useful
count information. To keep the implementation and validation cost low, a
reasonable degree of inaccuracy in the counts is acceptable. Arm does not
define a reasonable degree of inaccuracy but recommends the following
guidelines:

* Under normal operating conditions, the counters must present an accurate
  value of the count.
* In exceptional circumstances, such as a change in Security state or other
  boundary condition, it is acceptable for the count to be inaccurate.
* Under very unusual, non-repeating pathological cases, the counts can be
  inaccurate. These cases are likely to occur as a result of asynchronous
  exceptions, such as interrupts, where the chance of a systematic error in the
  count is very unlikely.

  > NOTE
>
> An implementation must not introduce inaccuracies that can be triggered
> systematically by the execution of normal pieces of software. For example, it
> is not reasonable for the count of branch behavior to be inaccurate when
> caused by a systematic error generated by the loop structure producing a
> dropping in branch count.
>
> However, dropping a single branch count as the result of a rare interaction
> with an interrupt is acceptable.

The permitted inaccuracy limits the possible uses of the Performance Monitors.
In particular, the architecture does not define the point in a pipeline where
the event counter is incremented, relative to the point where a read of the
event counters is made. This means that pipelining effects can cause some
imprecision, and can affect which events are counted.

Where a direct write to a Performance Monitors control register disables a
counter, and is followed by a Context synchronization event, any subsequent
indirect read of the control register by the Performance Monitors to determine
whether the counter is enabled will return the updated value. Any subsequent
direct read of the counter or counter overflow status flags will return the
value at the point the counter was disabled.

> Note
>
> The imprecision means that the counter might have counted an event around the time the counter was disabled, but
> does not allow the event to be observed as counted after the counter was disabled.

A change of Security state can also affect the accuracy of the Performance
Monitors, see Interaction with EL3 on page D11-5245.

In addition to this, entry to and exit from Debug state can disturb the normal
running of the PE, causing further inaccuracy in the Performance Monitors.
Disabling the counters while in Debug state limits the extent of this
inaccuracy. An implementation can employ methods to limit this inaccuracy, for
example by promptly disabling the counters during the Debug state entry
sequence.

An implementation must document any particular scenarios where significant
inaccuracies are expected.
